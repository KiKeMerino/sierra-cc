# Predicci칩n de la cobertura de nieve con un modelo NARX

## Descripci칩n

Este proyecto tiene como objetivo crear conciencia sobre c칩mo va a ir cambiando el nivel de la capa de nieve en fechas futuras utilizando un modelo NARX (Non-linear Autoregressive with Exogenous Inputs).

La funcionalidad de este c칩digo es tomar un modelo de red neuronal recurrente (RNN) que has entrenado para predecir 'area_nieve' bas치ndose en valores pasados de s칤 misma y de otras variables (ex칩genas), y utilizar ese modelo para predecir valores futuros de 'area_nieve' m치s all치 de los datos que se utilizaron para entrenar y evaluar el modelo

## Estructura de los datos

Los datos utilizados que usar칠 en este proyecto contienen los siguientes datasets de la nasa del sat칠lite MOD10A1F:

* CGF_NDSI_Snow_Cover: **Este ser치 el que nos interesa**
    - long_name: 'cloud-gap-filled NDSI snow cover',
    - valid_range: [0, 100],
    - FillValue: 255,
    - Key:
        - **40 - 100 = NIEVE (1)**

        - 0-100 = NDSI snow,
        - 200 = missing data,
        - 201 = no decision,
        - 211 = night,
        - 237 = inland water,
        - 239 = ocean,
        - 250 = cloud,
        - 254 = detector saturated,
        - 255 = fill

* Cloud_Persistence
    - long_name:
    - cloud persistence for preceding days,
    - valid_range: [0, 254],
    - FillValue: 255,
    - Key:
        - count of consecutive preceding days of cloud cover

Cada dataset es un raster de datos diviendo la basin en p칤xeles con los valores arriba mencionados, en este proyecto se considerar치n los valores entre 40 y 100 como nieve, y los dem치s como no nieve para simplificar el modelo

# Estructura del Dataset CGF_NDSI_Snow_Cover _(snow_cover)_
Este es el Dataset con el que trabajaremos, se trata de un xarray que contiene datos de cubierta de nieve derivados de imagenes MODIS, su estructura principal es la siguiente:
* **Dimensiones:**
    * `y`: Coordenadas de latitud
    * `x`: Coordenadas de longitud
    Se puede acceder a las coordenadas de latitud con `snow_cover.y.values` y a las de longitud con `snow_cover.x.values`.
* **Variable principal:**
    * `CGF_NDSI_Snow_Cover`: Representa el 칈ndice de Nieve de Diferencia Normalizada (NDSI), indicando la fracci칩n de cubierta de nieve en cada p칤xel.
    Los valores de cubierta de nieve se acceden directamente a trav칠s de `snow_cover["CGF_NDSI_Snow_Cover"]`.


## 1. Obtenci칩n de Datos <a name="id1"> </a>

Los datos MODIS se obtuvieron de [EarthData Search](https://search.earthdata.nasa.gov/search), la plataforma de NASA para la b칰squeda de datos geoespaciales. Los pasos para la descarga personalizada fueron los siguientes:

1.  **Filtrado por Fecha y 츼rea de Inter칠s:**
    * Se filtraron los datos por el rango de fechas deseado y se defini칩 el 치rea de inter칠s correspondiente a la basin Adda-Bormio mediante un archivo .zip que contiene el .shp para delimitar el per칤metro.

2.  **Descarga Personalizada:**
    * Se seleccion칩 la opci칩n de descarga personalizada para tener control sobre el formato y la proyecci칩n de los datos.
        * ![Primera opci칩n](images/option1.png)
3.  **Reproyecci칩n geoespacial (Latitud/Longitud):**
    * Se solicit칩 que los datos fueran re proyectados al sistema de coordenadas geogr치ficas (latitud/longitud). Por defecto, los datos MODIS se proporcionan en proyecci칩n sinusoidal, que no es adecuada para muchos an치lisis comunes.
        * ![Segunda opci칩n](images/option2.png)
    * Es importante reproyectar los datos antes de la descarga para simplificar el procesamiento posterior.

    ## 游 Tipo de Modelo: NARX (Nonlinear AutoRegressive with eXogenous inputs)

Nuestro modelo se basa en la arquitectura **NARX (Nonlinear AutoRegressive with eXogenous inputs)**, que se implementa mediante **Redes Neuronales Recurrentes (RNN)** con **capas LSTM (Long Short-Term Memory)**.

## 2. Arquitectura del modelo

### 쯈u칠 es NARX?

**NARX** es una clase de modelos de series temporales que predice un valor futuro de una variable bas치ndose en:
* **Auto-Regresivo (AR):** Valores pasados de la misma variable (en este caso, el 치rea de nieve).
* **Variables Ex칩genas (X):** Valores pasados y/o presentes de otras variables externas que influyen en la variable objetivo. Para este proyecto, estas variables ex칩genas incluyen:
    * `temperatura`
    * `precipitacion`
    * `dias_sin_precip`
    * (`precipitacion_bool`, `year`, `month`) tambi칠n presentes en los datos, en algunos modelos los incluir칠 y en otros no, para comprobar rendimiento y m칠tricas
* **No Lineal (N):** Las relaciones entre las entradas y la salida no son lineales, lo que permite al modelo capturar din치micas complejas. Las redes neuronales son la elecci칩n ideal para modelar estas relaciones no lineales.

### 쯇or qu칠 LSTM?

Las **LSTM** son un tipo avanzado de capa de red neuronal recurrente. Su principal ventaja es su capacidad para aprender y recordar dependencias a largo plazo en secuencias de datos. Esto es crucial para la predicci칩n de series temporales, donde el estado actual del sistema (치rea de nieve) puede depender de eventos que ocurrieron hace mucho tiempo. A diferencia de las RNN tradicionales, las LSTM superan el problema del "gradiente desvanecido" mediante "puertas" internas que controlan el flujo de informaci칩n, permiti칠ndoles retener informaci칩n relevante y descartar la irrelevante a lo largo de extensas secuencias.

### Arquitectura del Modelo Espec칤fico

Se entrena un modelo NARX-LSTM independiente para cada cuenca, lo que permite una especializaci칩n y adaptaci칩n a las caracter칤sticas 칰nicas de cada una. La arquitectura de cada modelo es la siguiente:

* **Capa de Entrada:** `input_shape = (n_lags_area, 1 + num_variables_exogenas)`
    * Recibe secuencias de longitud `n_lags_area` (ej. 3) de datos. Cada elemento de la secuencia es un vector que contiene el 치rea de nieve escalada y las variables ex칩genas escaladas para un momento dado.
* **Capa LSTM:** `LSTM(n_units_lstm, activation='relu')` Una capa recurrente que procesa la secuencia de entrada. Aprende y extrae patrones temporales y relaciones no lineales. Se configura con 2 par치metros:
    *  n_units_lstm: numero de neuronas, cuanto mayor sea este n칰mero mayor capacidad para aprender patrones y relaciones complejas pero mayor coste computacional y mayor riesgo de 'overfitting'
    *  Funcion de activaci칩n, en este caso "relu" (Rectified Linear Unit): introduce no linealidad, permitiendo que la red aprenda y modele relaciones m치s complejas y no lineales en los datos.
* **Capa Densa de Salida:** Una capa totalmente conectada con una 칰nica neurona, que produce la predicci칩n del 치rea de nieve para el siguiente paso de tiempo ($t+1$).
    * `Dense(1)`

## 3. Preprocesamiento de los datos

En este apartado se juntar치n todas las variables que nos intesan para nuestro modelo del apartado anterior y se analizar치 el dataset resultante, haremos lo siguiente:

1. EDA: exploracion de los datos
Lo primero ser치 juntar los 2 csv creados anteriormente haciendo coincidir las fechas, el resultado ser치 un dataframe de este estilo:
![Ejemplo genil-dilar](images/genil-dilar(head).png)

Este es el resultado de juntar los dos dataframes creados anteriormente, sin embargo a침adir칠 una columna m치s para mejorar el modelo "dias_sin_precip" que contar치 los dias transcurridos desde la 칰ltima precipitaci칩n
![D칤as sin precipitaci칩n](images/dias_sin_precip.png)


## 4. Distribuci칩n de ficheros
El proyecto se divide en 2 grandes partes: el disco externo y el directorio en el que se encuentra este mismo README

Dentro del disco externo habr치 dos directorios:
- **data:** en el que se encontrar치n todos los CSVs y los archivos hdf descargados
    ->
- **models:** en el que habr치 una carpeta por cada cuenca que contendr치 el mejor modelo para esa cuenca asi como sus m칠tricas, y gr치ficas relevantes con respecto a las predicciones:
    - *future_predictions*: se mostrar치n las predicciones de los 5 modelos en los 4 escenarios posibles en cada cuenca 
    - *graphs_adda-bornio*: gr치ficas sobre el rendimiento del modelo comparado con los datos reales
    - *metrics.json*: metricas e hiperpar치metros del modelo
    - *narx_model_adda-bornio.h5*: el modelos

![Ejemplo de la carpeta del modelo de adda-bornio](images/ejemplo-ficheros.png)

## 5. Ficheros 칰tiles

### 5.1. limpieza_datos.py
Este fichero contiene un conjunto de funciones 칰tiles para procesar los datos y crear diferentes csv, a continuaci칩n se detallar치n brevemente las funciones contenidas

- **process_basin(basin):** funci칩n principal que calcula el area de la cuenca *'basin'*. Procesa cada uno de los archivos hdfs y calcula el area de nieve, el resultado se guarda en *EXTERNAL_DISK/data/csv/areas/*
- **process_var_exog(input_file, output_path, save=False):** coge el excel de series agregadas y lo convierte a csv separ치ndolo y renombrando las columnas. Devuelve un csv con todas las variables ex칩genas y con una nueva columna 'cuenca' que idenfica a qu칠 cuenca pertenece cada registro.
- **cleaning_future_series(input_data_path, output_data_path):** funci칩n que procesa el excel *EXTERNAL_DISK:\data\csv\Series_historicas-futuras.xlsx* y crea un csv con las varibles ex칩genas para cada escenario y cada modelo, en total saldr치n 20 csv distintos
- **join_area_exog(exog_file, areas_path, output_path = './datasets', save=False):** funci칩n para obtener el el dataset final de cada cuenca, coge como par치metro el csv de variables ex칩genas, el csv de areas calculado anteriormente y los junta, preparado para entrenar al modelo
- **impute_outliers(df, cuenca, columna, save=False):** funci칩n que coge un dataframe, y quita los outliers de la columna especificada por par치metro. Se considerar치 outlier cualquier valor por encima de *1.5 * rango_intercuartilico*

### 5.2. models/best_params.py
Programa muy 칰til que hace uso de la librer칤a optuna y se encarga de encontrar el mejor modelo para cada cuenca. Simplemente ejecutar el script y se pedir치 al usuario la cuenca que se desea optimizar y el n칰mero de ensayos que se quiere realizar. Cada ensayo tarda bastante por lo que se recomienda no usar un n칰mero demasiado alto, ej: 10-20.
Se guardar치n los hiperpar치metros del mejor modelo encontrado en un json, el cual se mostrar치 la ruta por pantalla
La m칠trica que se usa para la optimizaci칩n es el NSE (Nash Sutcliffe Efficiency)

### 5.3. models/create_load_model.py
Una vez se conocen la mejor configuraci칩n, para un modelo, este script crear치 o evaluar치 un nuevo modelo y se crear치n gr치ficas para mejor visualizaci칩n. Al igual que el fichero anterior, simplemente se ejecuta y el programa se encargar치 de pedir los datos al usuario

### 5.4. models/predictions.py
Este script pide al usuario el nombre de una cuenca, y el escenario del que se desea obtener la predicciones: obtiene los datasets de variables ex칩genas de cada modelo para ese escenario y genera una gr치fica en la que se visualizan las diferentes predicciones y un csv con las predcicciones de cada modelo.

### 5.5. heatmaps.py
Se encarga de generar los mapas de probabilidad de que cada pixel est칠 cubierno o no de nieve, leyendo los archivos hdf.
쮺omo usar?
Simplemente llamar a la funcion, save = True para guardar los resultados o False simplemente para mostrarlos por pantalla 

### 5.6. environment-hdf.yml & tf210_gpu.yml (IMPORTANTE)
Entornos para que funcione el proyecto correctamente, tanto para heatmaps.py como para algunas funcionalidades de limpieza_datos.py es necesario tener activo el entorno *environment-hdf.yml*. Para el resto usaremos *tf210_gpu.yml* ya que usar치 la versi칩n 2.10 de TensorFlow (libreria para machine learning) y har치 uso de la gpu (si el pc est치 configurado para ello) para procesar los datos m치s rapidamente. 

Para instalar el entorno simplemente habr치 que ejecutar *conda env create -f tf210_gpu.yml*
*conda env list* para comprobar que el entorno se ha creado correctamente y *conda activate tf210_gpu* para activar nuestro nuevo entorno